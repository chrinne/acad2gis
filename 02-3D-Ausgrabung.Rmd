--- 
title: "CAD-Dokumentation zu GIS mit SpatiaLite migrieren"
author: "Christoph Rinne"
date: "`r format(Sys.time(), '%d. %B %Y')`"
output:
  pdf_document:
    fig_caption: true
    number_sections: true
    toc: true
    toc_depth: 4
    df_print: kable
  html_document:
    toc: true
    toc_depth: 4
    toc_float: true
    number_sections: true
license: CC-BY-SA 4.0
header-includes: \renewcommand{\contentsname}{Inhalt} \renewcommand{\figurename}{Abb.}
  \renewcommand{\tablename}{Tab.}
bibliography: ./inst/references.bib
csl: ./inst/journal-of-archaeological-science.csl
papersize: a4
email: crinne@ufg.uni-kiel.de
urlcolor: blue
link-citations: yes
linkcolor: blue
number_sections: yes
lang: de-DE
description: Handreichung zur Bereinigung und Migration von CAD-Dokumentation von
  Ausgrabungen zur SpatiaLite.
---

\newpage

# Vorwort {-}



```{r R-script-load-library-setup-connection, include=FALSE}
library(RSQLite)
juffdb<-dbConnect(RSQLite::SQLite(), dbname = "./data/JUff.sqlite")
```

```{sql basic-table-drop, eval=FALSE, connection=juffdb, include=FALSE}
Drop table if exists hatch_layer_2d;
Drop table if exists hatch_layer_2D_pattern;
Drop table if exists line_layer_2d;
Drop table if exists polyg_layer_2d;
Drop table if exists text_layer_3d;
Drop table if exists text_layer_3d_attr;
```


# Einführung

Ziel ist die Überführung von Ausgrabungsplänen aus CAD-Dateien in ein GIS. Ausgang ist der CAD-Plan einer Ausgrabung für ein Landesdenkmalamt über insgesamt drei Ausgrabungsphasen mit einem Personalwechsel bei der Ausgrabungsleitung und der Grabungstechnik [^1]. Der dargestellte Weg ist einer von vielen möglichen Wegen.

[^1]: Genehmigung des Amtes und der Ausgräberin noch erbitten.

**Anmerkungen** 

 - Menüpfade oder Abfolgen von Fenstern werden mit schlichten Pfeilen dargestellt: "Datei > Speichern". 
 - Tastaturkürzel, die ich gerne Nutze, stehen in Spitzklammern je Taste: \<strg> + \<c>. 
 - Schalter auf Formularen werden in [] gesetzt: [OK] 
 - Zur Darstellung von Befehlen im Text nutze ich die in Markdown übliche Darstellung von Code oder eben Anweisungen an den Computer: ```anweisung```. 
 - SQL-Anweisungen sind nicht in Großbuchstaben gesetzt, die farbliche Gestaltung macht dies überflüssig. Eine Ausnahme bilden die verwendeten Funktion bei denen der *CamelCase* für die bessere Lesbarkeit beibehalten wird. Auch wird der Anfang einer  Anweisungen jeweils großgeschrieben, um aufeinander folgende Anweisungen etwas besser zu trennen. Im vorliegenden Fall wurden Leerzeichen in Objektnamen vermieden, dadurch müssen Tabellen und Feldnamen nicht in "" stehen.
 - Der Text enthält viele Links die auf Papier nicht funktionieren. Sparen Sie bitte Papier und verzichten Sie auf den Ausdruck. 

## Verwendete Software & Informationen

 - OS Windows 10
 - QGIS 3.22.4-Białowieża Quelle: [https://qgis.org]
 - SpatiaLite SpatiaLite GUI 2.1.0 beta1, SpatiaLite 5.0.0, SQLite 3.33.0, Quelle [http://www.gaia-gis.it]
 - AutoCAD 2010, Quelle für aktuelle *kostenlose* Schulversionen:  [https://www.autodesk.de/education/edu-software/overview]
 
 - SpatiaLite Cookbook html [http://www.gaia-gis.it/gaia-sins/spatialite-cookbook/index.html]
 - SpatiaLite Funktionen [http://www.gaia-gis.it/gaia-sins/spatialite-sql-5.0.0.html] 

AutoCAD ist eine sehr komplexe Software und Ausgrabungen können eine komplexe Struktur annehmen, die es zu dokumentieren gilt. Erwarten Sie nicht, dass die notwendige Kompetenz beim Erstellen der digitalen Daten stets vorhanden war, auch der Autor (Chr. Rinne) ist hier nur Autodidakt. 

Rechnen Sie mit Fehlern im originalen Datenbestand und einer ggf. nicht optimalen Struktur oder erwarten Sie auch nicht die von Ihnen bevorzugte Struktur. Korrektur von Fehler und Anpassungen der Struktur erfolgen sicher am besten im originalen Arbeitsumfeld, also CAD.

Neben AutoCAD gibt es teils kostengünstigere Alternativen, u.a.:

 - BricsCAD [https://www.bricsys.com]
 - MegaCAD [https://www.megacad.de/]
 
# Jakob-Uffrecht-Straße

## AutoCAD Quelldatei (dxf)

Es handelt sich um einen mehrperiodigen Siedlungs- und Bestattungsplatz. Untersucht wurden gut 8.300 m² mit 589 Befunden, überwiegend der Bronzezeit (316), 11 eindeutig neolithischen Befunden, darunter ein doppeltes Grabensystem, 260 nicht weiter datierten oder allgemein urgeschichtlichen und zwei neuzeitlichen Befunden. Zu dem CAD Plan liegen für jede Ausgrabung eine Datenbank (MS Access) mit weiteren Informationen vor. Diese Daten können nach der Aufarbeitung des CAD Planes mit den dann eindeutig benannten Befunden verbunden werden. Dies ist aber nicht Teil dieses Skriptes. 

![Abb. 1 CAD-Datei Jacob-Uffrecgt-Straße in AutoCAD](./img/03_JUff_cad_overview.png)

Die Zeichnung enthält 171 Polylinien (2D), 33 Kreise (2D), 263 Absatztexte (MText), 361 Linien (3D), 239 Schraffuren, 427 Blockreferenzen, 810 Polylinien (3D), 497 einfache Texte und 369 Punkte (3D). In dieser Liste fallen vor allem zwei Objektypen auf, die Kreise und der Absatztext. Die Kreise wurden für einige Befunde verwendet und liegen als flache Geometrie auf einer sinnvollen Höhe. Der Absatztext wurde bei einer Maßnahme für die Befundnummern verwendet. Da es sich um keine "normale" Geometrie handelt und nur die Textbox aber nicht der Text einen Lagebezug zu den Koordinaten der Grabung hat muss dies noch in AutoCAD aufgelöst werden. 
Ebenfalls interessant, auch mit Blick auf die Umsetzung in SpatiaLite, sind  als 2D-Polylinien mit Erhebung vorliegende Befunde. Nutzen Sie ```_qselect``` mit den Optionen Objekttyp: Polylinie und der Eigenschaft Layer=Befund, um diese pauschal auszuwählen und mit einer Farbvorgabe, z.B. Magenta, deutlich hervorzuheben.  

```{r 'Table 1 List of layers in the dwg.', echo=FALSE}
tab01<-read.table("./data-raw/JUff_layer.tab", header = TRUE, sep = "\t", dec = ",")
# if output is html table as interactive datatable else table with limit
if (knitr::is_html_output()) {
  DT::datatable(tab01, filter = "top", options=list(pagelength=10), caption="Liste der
 Planzeichnungen und erstellten DWG-Dateien.")
} else {
  knitr::kable(tab01)
}
```

Eine weitere Kontrolle ergibt:

- Die Anzahl der Layer ist überschaubar, eine Trennung nach den Grabungsflächen ist nicht erfolgt, die Namen sind leider nicht ganz stringent, vor allem die Befundnummern sind mehrfach vertreten.
- Einige Namen verweisen auf konkrete Objekte und entsprechen damit nicht der scheinbar allgemein angewendeten Nomenklatur. 
- Es sind keine weiteren BKS (Benutzerkoordinatensysteme) definiert, die Koordinaten lassen ein GKB Zone 4 vermuten (das Elipsoidmodell ergibt sich daraus aber nicht).
- Die Einheit ist erwartbar in Millimeter statt den verwendeten Meter.
- Zahlreiche Befundlinien sind nicht geschlossen, auf dem Befundlayer liegen auch Kreise.
- Die Befundnummern sind über die einzelnen Ausgrabungen nicht fortlaufend vergeben, es gibt somit doppelte Befundnummern in der nördlichen und südlichen Fläche. 
- Die Ansicht von der Seite offenbart das größte Problem. Vielfach laufen Polygone von der realen Höhe auf 0 runter.  Daneben sind aber auch in der Grabung mehrere Höhenbereiche der Objekte mit einzelnen Verbindungslinien zu erkennen. Falsche Prismenhöhe beim Messen?

Es ist vor allem dieses letzte Problem, das bei der nachfolgenden Aufarbeitung besonders betrachtet werden soll. 

*Wichtig* Der MText wird weder von SpatiaLite noch von QGIS beim Import der DXF-Datei erkannt. Der Export dieser Objekte in AutoCAD über "Extras > Datenextraktion" ist möglich, der Inhalt wird aber auf den Ursprung der Textbox bezogen und die ggf. mehrzeiligen Texte werden als ein Textfeld hieran angehängt wodurch sich jede Zeile in Abhängigkeit der Texthöhe zunehmend von der Koordinate entfernt. Es empfiehlt sich, MText mit dem Befehl ```ursprung (_explode)``` in einfachen Text aufzulösen. Damit wird er auch beim Import der DXF-Datei je Zeile als Text erkannt und dem Einfügepunkt, meist der linke Ursprung der Basislinie, zugewiesen.

Um MText pauschal in Text umzuwandeln selektieren sie diesen pauschal mit ```qselect```, Anwenden auf: Ganze Zeichnung, Objekttyp: MText, Eigenschaft: Farbe = VonLayer, "In neuen Auswahlsatz einfügen" und [OK]. Danach den Befehl ```ursprung``` für die ausgewählten Objekte eingeben und ausführen. Da unter Umständen MText nicht die Farbe des Layers gehabt haben kann sollten Sie erneut alles Markieren und im Fenster der Eigenschaften (``eigenschaften```) im oberen drop-down die Anzahl der vorhandenen Objekttypen auf MText kontrollieren.

## SpatiaLite GUI

Nach dem Start der GUI bitte "Menu > Create a new (empty) SQLite DB" ausführen. In diese wird die dxf-Datei mit der gesamten Ausgrabung importiert: "Menu > Advanced > Import DXF drawings". Im Fenster zum Import bitte folgende Angaben: (x) Import selected DXF drawing file only, SRID: 31467, [v] Append to already existing tables, Dimensions: (x) authomatic 2D/3D, (x) mixed layers, Special Rings handling (x) none. Diese Angaben beziehen sich auf den aktuellen Import und müssen ggf. angepasst werden. Die Option 'mixed layers' trennt nur die Typen (Punkt, Linie Polygon, Text), die Layer werden als Attribut (Spalte) angelegt. Die Alternative trennt erst die Layer und dann nach Typen, erstellt also das x-Fache der vorhandenen CAD-Layer als Tabellen.

Als Ergebnis sind folgende Tabellen mit den Spalten *feature_id*, *filename*, *layer* und *geometry* vorhanden:

- hatch_layer_2d
- hatch_layer_2d_pattern
- line_layer_3d
- point_layer_3d
- polyg_layer_3d
- text_layer_3d

### Datenkontrolle

Visualisieren Sie den Inhalt der Geometrietabellen in QGIS. Die Option "Map preview" im Kontextmenü zu jeder Geometriespalte der Tabellen in SpatiaLite ist oft hilfreich, bietet aber weniger Möglichkeiten. Ergänzend wird in SpatiaLite für jede Tabelle eine zusammenfassende Übersicht der Daten generiert. 

Die Tabelle **hatch_layer_2d** scheint ein vollständiges(?) Abbild der dokumentierten Befunde. Sie resultiert aus den Schraffuren zur Datierung oder Befundansprache, die auf jeweils eigenen Layern in AutoCAD abgelegt wurden. Diese Informationen sind nett, sollten aber als Sachinformationen später aus den vorhandenen Datenbanken an die Befundnummern angehängt werden (join). Einige Geometrien scheinen fehlerhaft (NULL).

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Select layer, GeometryType(geometry) as geomtype, Count(*) as n 
from hatch_layer_2d
group by 1, 2;
```

Die Tabelle **hatch_layer_2d_pattern** sieht ähnlich aus, liefert aber nur zwei Geometrien, die überwiegenden Fälle sind NULL. 

In AutoCAD bestehen **Füllungen** (Pattern) wie bei vielen Grafikprogrammen aus zwei Elemente: der Kontur (Umgrenzung) und der Füllung. AutoCAD verwendet überwiegend Schraffuren, teils komplexe Kombinationen aus Linien, Polygonen und Punkten. Daneben gibt es die Füllung "solid", die eher eine Ausnahme darstellt. Erstere finden sich in der Tabelle mit mit der Ergänzung "_pattern"- letztere in der Tabelle ohne die Extension. Schraffuren sind in AutoCAD Flächen und damit sind diese Geometrien auch hier 2D. 

- Die vorgenannten Tabellen sind damit weitgehend wertlos, denn die 2D Geometrie ist ohne z-Wert unzureichend und die Sachinformationen stehen in der zugehörigen Datenbank des Projektes. 

Die Tabelle **line_layer_3d** ist von zentraler Bedeutung und zeigt außer der nicht stringenten Benennung der Layer keine Auffälligkeiten. Allerdings irritiert der mangelhafte Bezug der Profile zu den Layern (00Profil, Profile). Zudem sind offenbar zahlreiche Befunde nur als Linien erkannt worden. Die Profile weisen mit "Ansichtshaken" auf die jeweils dokumentierten Seite hin.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select layer, GeometryType(geometry) as geomtype, Count(*) as n 
from line_layer_3d
group by 1, 2;
```

Die Tabelle **point_layer_3d** enthält 3D-Punkte, die durch die Layerbezeichnungen teilweise von Bedeutung sind. Überwiegend sind es Höhenwerte der einzelnen Befunde die aber keinen Planumsbezug oder benannten Befundbezuge haben und mit den vorliegenden z-Polygonen für die Befunde überflüssig sind. Von interesse erscheinen die Verweise auf Funde (Keramik, Knochen) und Messbildnägel für die Photgrammetrie. 

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select layer, GeometryType(geometry) as geomtype, Count(*) as n 
from point_layer_3d
group by 1, 2;
```

Die Tabelle **polyg_layer_3d** ist von zentraler Bedeutung. Es handelt sich überwiegend um Befunde und einige Flächengrenzen auf unterschiedlichen Layern. Irritierend ist ein Profilpolygon und ein als Polygon dokumentiertes Keramikfargment. Bei ersterem  handelt es sich um zwei, gemeinsam als Kasten ausgehobene Profile zu zwei dicht beieinander liegenden Befunden.  

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select layer, GeometryType(geometry) as geomtype, Count(*) as n 
from polyg_layer_3d
group by 1, 2;
```

Die Tabelle **text_layer_3d** hat zu den oben genannten Spalten noch *label* und *rotation*. Es sind überwiegend die Befund- und Profilnummern, dazu einige weitere Beschriftungen. Die im CAD-Plan als Block mit Attribute gesetzten Niv-Werte sind nicht dabei und müssen über die Datenextraktion und die resultierende CSV-Liste wieder importiert werden.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select layer, GeometryType(geometry) as geomtype, Count(*) as n 
from text_layer_3d
group by 1, 2;
```

### Topologie prüfen und reparieren

Zur Datenbereinigung werden in allen Geometriespalten pauschal ungültige Geometrien repariert.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Begin transaction;
Update line_layer_3d
 set geometry = SanitizeGeometry(geometry);
Update point_layer_3d
 set geometry = SanitizeGeometry(geometry);
Update polyg_layer_3d
 set geometry = SanitizeGeometry(geometry);
Update text_layer_3d
 set geometry = SanitizeGeometry(geometry);
Commit;
```

In der Tabelle **line_layer_3d**  bleiben vier Fälle, die nur aus zwei identischen Punkten bestehen. Diese sind schlicht wertlos und werden gelöscht.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Begin transaction;
select *, IsValidReason(geometry), st_AsText(geometry) from line_layer_3d
where isvalid(geometry) <> 1;
Delete from line_layer_3d
where isvalid(geometry) <> 1;
Commit;
```

In der Tabelle *polyg_layer_3d* sind zwei sich selbst überschneidende Gemoetrien. Die visuelle Prüfung zeigt erst kein offensichtliches Problem, in einem Fall ist bei sehr kleinem Maßstab eine Kreuzung der Kontur durch sehr dicht gesetzte Punkte zu erkennen. Bei der Einmessung wurde das Prisma entweder zu stark geneigt, wodurch der Messpunkt hinter den vorangehenden berechnet wurde oder aber der Endpunkt der Linie wurde über versehentlich den Startpunkt hinaus gemessen. Beides kann leicht passieren und ist hier sicher nicht die Ausnahme. 

Eine schnelle, zielorientierte Lösung scheint angebracht. Zuerst wird die Funktion st_makevalid() angewendet. Diese erstellt bei Überschneidungen aber ein Multipolygon und damit hier nicht zulässige Geometrien die auszuschließen sind. 

Das Polygon wird mit der Funktion ST_SimplifyPreserveTopology() unter Wahrung der Topologie und einer relativ geringen Toleranz von 0.05 m vereinfacht. Da hierbei aber alle Punkte des Polygons berücksichtigt werden weicht die Fläche doch erkennbar vom Original ab und es werden zudem mit der Funktion ST_Snap() die Knoten und die Kanten erneut an das original mit der selben Toleranz gefangen. Im Ergebnis liegt ein valides z-Polygon sehr großer Ähnlichkeit vor. 

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Begin transaction;
-- Probleme lokalisieren
select *, IsValidReason(geometry) from polyg_layer_3d
  where IsValid(geometry) <> 1;
-- Die erste einfache Problemlösung
Update polyg_layer_3d
  set geometry = ST_MakeValid(geometry)
  where IsValid(geometry) <> 1 and CastToSingle(ST_MakeValid(geometry)) not null;
-- Die zweite einfache Problemlösung im Vergleich
select st_area(ST_SimplifyPreserveTopology(geometry,0.05)) as simple_area, 
st_area(geometry) as orig_area, 
st_area(st_snap(ST_SimplifyPreserveTopology(geometry,0.05),geometry,0.05)) as snap_simple_area,
geometrytype(st_snap(ST_SimplifyPreserveTopology(geometry,0.05),geometry,0.05)) as snap_simple_type,
st_isvalid(st_snap(ST_SimplifyPreserveTopology(geometry,0.05),geometry,0.05)) as snap_simple_valid
from polyg_layer_3d
where isvalid(geometry) <> 1;
Commit;
```

| simple_area | orig_area | snap_simple_area | snap_simple_type | snap_simple_valid |
| ---------:| ---------:| ---------:|:---------:| ---------:|
| 1.699869 | 1.729045 | 1.729621 | POLYGON Z | 1 |

Das verbleibende ungültige Polygon wird mit dieser letzten Methode repariert.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Update polyg_layer_3d
  set geometry = st_snap(ST_SimplifyPreserveTopology(geometry,0.05),geometry,0.05)
  where isvalid(geometry) <> 1;
```

Alternativ könnten die aus ST_MakeValid() resultierenden Multipolygone aufgelöst, verglichen als auch bewertet und resultierend nur das repräsentative zum Original aufgehoben werden. Der Aufwand ist hier deutlich größer. Für die hier aufgezeigte Problemlösung muss aber:
- das eingangs dargestellte Problem kleiner Überschneidungen vorliegen und
- eine dem Maßstab als auch der Dimension angemessene Toleranz gewählt werden. 

### Höhenfehler korrigieren

Problem: Einzelne Punkte von Linien oder Polygone wurden an anderen Objekten gefangen oder von Hand gezeichnet, damit haben diese erkennbar einen falschen Z-Wert. Zum Beispiel:

- Die als Blöcke mit Attribut um die nördliche Grabungsfläche auf der Obrfläche eingemessenen Niv-Werte liegen bei 52,3 m im Westen und zwischen 53,0 und 53,4 m im Norden und Osten. Befundgrenzen sollten demnach mindestens 0,3 m unter diesen Werten liegen. 
- Im Norden grenzen einige Befunde an die Schnittgrenze und die Befundlinien des Planum 1 fangen die Schnittgrenze auf dem Planum 0. 
- Die Ansichtshaken der Profile sind von Hand gezeichnet und fallen damit auf die Höhe Null.
- Einige Befunde scheinen von Hand entlang gemessene Befundgrenzen konstruiert worden zu sein wobei die ohne Objektfang erstellen Knoten die Höhe 0 haben. 

Daneben kann auch das grundsätzliche Problem einer falschen Prismenhöhe vorliegen. Daran schließt sich die Frage nach dem ursprünglich, richtigen z-Wert an, die aber nur näherungsweise beantwortet werden kann. Mögliche, annähernd korrekte Werte sind die nicht bei 0 liegenden z-Werte vor und hinter dem Knoten, der Durchschnitt oder Median der z-Wert des Polygons ohne die eindeutig "falschen" Werte oder der z-Wert des nächsten gemessenen Höhenwertes oder oder oder. Dazu kommt noch das Problem großen Polygonen wir der Grabungsfläche, die bei größzügiger Vermessung durch aus einen deutlichen Höhenunterschied von Punkt zu Punkt aufweisen können.  

#### Tabelle Blöcke mit Attribut \newline

Importieren wir deshalb als erstes die in AutoCAD exportierten Blöcke mit Attribut (Datenextraktion). Über das Menü "Menu > Advanced > Load CSV/TXT" rufen Sie das Importfenster auf, wählen die Datei "JUff_blockattr.csv", Table name: block_layer_3d, [x] First line contains ..., Text separator: [o] none, Column seperaor: [o] Comma, Decimal separator: Point und Charset Encoding: UTF-8 (ganz am Ende). Die Spalte sind Namen (Blockname), HÖHE (Attribut), Layer (Layer des Blocks), Position_X/Y/Z (Koordinaten des Blocks) und Nummer (Attribut). Nachfolgend werden zuerst eine Geometrie aus den Koordinaten und dann ein Überblick über die vorhandenen z-Werte erstellt.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Begin transaction;
Select AddGeometryColumn('block_layer_3d', 'geometry', 31468, 'POINTZ', 'XYZ');
Update block_layer_3d 
  set geometry = ST_GeomFromText('POINTZ(' || "Position_X" || ' ' || 
  "Position_Y" || ' ' || "Position_Z" || ')', 31468);
select max(HÖHE) as max_H, min(HÖHE) as min_H, max(Position_Z) as max_Z,
  sum(Position_Z) / count(Position_Z) as mean_Z, min(Position_Z) as min_Z
from block_layer_3d group by name;
Commit;
```

| Name | max_H | min_H | max_Z | mean_Z | min_Z |
| ----- |---:| ---:| ---:| ----:| ---:|
| HP_FERTIG_OBERKANTE | 53.690 | 50.540 | 53.832 | 51.724 | 0.126 |
| HP_OHNE_SYMBOL | 51.450 | 51.450 | 51.590 | 51.590 | 51.590 |
| MESSPUNKT |  |  | 52.920 | 52.507 | 50.977 |

Insgesamt scheinen die Messwerte plausibel zwischen 51 m und 54 m über NN zu liegen, doch auch hier gibt es bei den gemessenen z-Werten offensichtlich falsche Werte nahe 0.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select max(st_maxz(geometry)) as max_maxz,
max(st_minz(geometry)) as max_minz, 
sum(st_maxz(geometry) - st_minz(geometry)) / count (*) as mean_diff,
min(st_maxz(geometry) - st_minz(geometry)) as min_diff,
max(st_maxz(geometry) - st_minz(geometry)) as max_diff
from line_layer_3d;
```

| max_maxz | max_minz | mean_diff | min_diff | max_diff |
| --------:| --------:| ---------:| --------:| --------:|
| 105.604000 | 105.604000 | 3.323629 | 0.000000 | 52.732000 |

Die selbe Abfrage, nur für die Tabelle polyg_layer_3d.

| max_maxz | max_minz | mean_diff | min_diff | max_diff |
| --------:| --------:| ---------:| --------:| --------:|
| 53.757953 | 53.026502 | 0.703233 | 0.000000 | 51.742000 |

Beginnen wir mit der Tabelle **block_layer_3d** und vertrauen wir darauf, dass die dargestellten, sichtbaren Höhenwerte visuell geprüft wurden und damit korrekt sein sollten. Wir verschaffen uns einen Überblick, indem wir die Differenz zwischen dargestelltem und gemessenen Wert (HÖHE - Position_Z) in Klassen von 1 cm zusammenfassen.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select count(*) as n, round((HÖHE - Position_Z)*100, 0) as diff_cm 
from block_layer_3d 
where abs(HÖHE - Position_Z) > 0.01
group by round((HÖHE - Position_Z)*100, 0);
```

| diff_cm | -152 | -114 | -21 | -18 | -17 | -16 | -15 | -14 | -13 | -9 | 22 | 5157 |
| :---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: |
| n | 1 | 1 | 1 | 1 | 1 | 1 | 2 | 283 | 7 | 1 | 1 | 1 |

Das transponierte Ergebnis zeigt sehr zahlreiche Abweichungen um -14 cm und nur vereinzelt über +/- 15 cm hinaus. Die Häufung bei -14 cm weist auf ein strukturelles Problem, für das aber keine Lösung unmittelbar auf der Hand liegt. Auch wenn die Differenz bis 15 cm eigentlich nicht vorhanden sein sollte wird diese nachfolgend ignoriert und nur die um mehr als +/- 14 cm abweichenden Messwerte mit den Angaben aus HÖHE korrigiert 

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Update block_layer_3d 
  set geometry = ST_GeomFromText('POINTZ(' || "Position_X" || ' ' || 
  "Position_Y" || ' ' || "HÖHE" || ')', 31468)
  where abs(HÖHE - Position_Z) > 0.14;
```

Die z-Werte aller Punkte liegen nun in einem plausiblen Wertebereich: Min.: 50.677, Max.: 53.829, Mittelw.: 51.981.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select min(ST_Z(geometry)) as min_z, max(ST_Z(geometry)) as max_z, 
  sum(ST_Z(geometry))/count(*) as mean_z
  from block_layer_3d;
```

#### Tabelle line_layer_3d \newline

Es folgt die Tabelle **line_layer_3d**. 




```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select st_maxz(geometry), st_npoints(geometry), st_astext(geometry) from line_layer_3d
where st_minz(geometry) = 0 and st_maxz(geometry) <> 0;
```

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select st_maxz(geometry), st_npoints(geometry), st_astext(geometry) from line_layer_3d
where st_minz(geometry) = 0 and st_maxz(geometry) <> 0;
```
Das liefer aber keine Einträge. Warum? MinZ ist nicht 0, sondern nahe 0. Also Schwellwert der Differenz definieren. Da nur potentielle Problemfälle gefunden werden sollen eher offensiv: hier 0.3 m.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select st_maxz(geometry) - st_minz(geometry) as d, 
	st_minz(geometry), st_maxz(geometry), st_npoints(geometry) 
from line_layer_3d
where  d > 0.3
order by d desc; 
```

Liefert 86 Linien mit potentiellem Z-Wert-Fehler.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
begin transaction;
drop table if exists line_layer_3d_err;
create temp table line_layer_3d_err as
select feature_id, geometry
from line_layer_3d
where  st_maxz(geometry) - st_minz(geometry) > 0.3;
select RecoverGeometryColumn('line_layer_3d_err', 'geometry', 31468, 'linestring', 'XYZ');
commit;
```

feature_id = 616 hat 4 Punkte

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
begin transaction;
drop table if exists line_err_multipoints;
CREATE TABLE line_err_multipoints AS 
select feature_id as line_feature_id, st_dissolvepoints(geometry) as geometry
from line_layer_3d
where  st_maxz(geometry) - st_minz(geometry) > 0.3;

Select RecoverGeometryColumn('line_err_multipoints', 'geometry', 31468, 'multipoint', 'XYZ');

drop table if exists line_err_points;
create table line_err_points as 
SELECT lmp.rowid, lmp.line_feature_id, e.item_no, 
  ST_x(e.geometry) as x, ST_y(e.geometry) as y, ST_Z(e.geometry) AS z
FROM line_err_multipoints AS lmp
JOIN ElementaryGeometries AS e ON (e.f_table_name = 'line_err_multipoints'
AND e.origin_rowid = lmp.rowid);
commit;

```

Jetzt noch über die Liste der Punkte laufen und falsche z-Werte ersetzen.
mean z-wert berechnen sum(z)/count(z) group by line_feature_id
case item_no = 0 and abs(z-wert - mean(z-wert)) > 0.3 dann item_no + 1
Anderen Z-Wert nachschlagen über item_no - 1 oder oder item_no + 1
Dann mittels aggregate, group_concat und 
polygonfromtext('POLYGON Z(' || group_concat(x || ' ' || y || ' ' || z, ', ') ||)', '|| srid)


```{sql, eval=FALSE, connection=juffdb, include=TRUE}
```

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
```

# Literatur