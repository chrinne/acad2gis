--- 
title: "CAD-Dokumentation zu GIS mit SpatiaLite migrieren"
author: "Christoph Rinne"
date: "`r format(Sys.time(), '%d. %B %Y')`"
output:
  pdf_document:
    fig_caption: true
    number_sections: true
    toc: true
    toc_depth: 4
    df_print: kable
  html_document:
    toc: true
    toc_depth: 4
    toc_float: true
    number_sections: true
license: CC-BY-SA 4.0
header-includes: \renewcommand{\contentsname}{Inhalt} \renewcommand{\figurename}{Abb.}
  \renewcommand{\tablename}{Tab.}
bibliography: ./inst/references.bib
csl: ./inst/journal-of-archaeological-science.csl
papersize: a4
email: crinne@ufg.uni-kiel.de
urlcolor: blue
link-citations: yes
linkcolor: blue
number_sections: yes
lang: de-DE
description: Handreichung zur Bereinigung und Migration von CAD-Dokumentation von
  Ausgrabungen zur SpatiaLite.
---

\newpage

# Vorwort {-}



```{r R-script-load-library-setup-connection, include=FALSE}
library(RSQLite)
juffdb<-dbConnect(RSQLite::SQLite(), dbname = "./data/JUff.sqlite")
```

```{sql basic-table-drop, eval=FALSE, connection=juffdb, include=FALSE}
Drop table if exists hatch_layer_2d;
Drop table if exists hatch_layer_2D_pattern;
Drop table if exists line_layer_2d;
Drop table if exists polyg_layer_2d;
Drop table if exists text_layer_3d;
Drop table if exists text_layer_3d_attr;
```


# Einführung

Ziel ist die Überführung von Ausgrabungsplänen aus CAD-Dateien in ein GIS. Ausgang ist der CAD-Plan einer Ausgrabung für ein Landesdenkmalamt über insgesamt drei Ausgrabungsphasen mit einem Personalwechsel bei der Ausgrabungsleitung und der Grabungstechnik [^1]. Der dargestellte Weg ist einer von vielen möglichen Wegen.

[^1]: Genehmigung des Amtes und der Ausgräberin noch erbitten.

**Anmerkungen** 

 - Menüpfade oder Abfolgen von Fenstern werden mit schlichten Pfeilen dargestellt: "Datei > Speichern". 
 - Tastaturkürzel, die ich gerne Nutze, stehen in Spitzklammern je Taste: \<strg> + \<c>. 
 - Schalter auf Formularen werden in [] gesetzt: [OK] 
 - Zur Darstellung von Befehlen im Text nutze ich die in Markdown übliche Darstellung von Code oder eben Anweisungen an den Computer: ```anweisung```. 
 - SQL-Anweisungen sind nicht in Großbuchstaben gesetzt, die farbliche Gestaltung macht dies überflüssig. Eine Ausnahme bilden die verwendeten Funktion bei denen der *CamelCase* für die bessere Lesbarkeit beibehalten wird. Auch wird der Anfang einer  Anweisungen jeweils großgeschrieben, um aufeinander folgende Anweisungen etwas besser zu trennen. Im vorliegenden Fall wurden Leerzeichen in Objektnamen vermieden, dadurch müssen Tabellen und Feldnamen nicht in "" stehen.
 - Der Text enthält viele Links die auf Papier nicht funktionieren. Sparen Sie bitte Papier und verzichten Sie auf den Ausdruck. 

## Verwendete Software & Informationen

 - OS Windows 10
 - QGIS 3.22.4-Białowieża Quelle: [https://qgis.org]
 - SpatiaLite SpatiaLite GUI 2.1.0 beta1, SpatiaLite 5.0.0, SQLite 3.33.0, Quelle [http://www.gaia-gis.it]
 - AutoCAD 2010, Quelle für aktuelle *kostenlose* Schulversionen:  [https://www.autodesk.de/education/edu-software/overview]
 
 - SpatiaLite Cookbook html [http://www.gaia-gis.it/gaia-sins/spatialite-cookbook/index.html]
 - SpatiaLite Funktionen [http://www.gaia-gis.it/gaia-sins/spatialite-sql-5.0.0.html] 

AutoCAD ist eine sehr komplexe Software und Ausgrabungen können eine komplexe Struktur annehmen, die es zu dokumentieren gilt. Erwarten Sie nicht, dass die notwendige Kompetenz beim Erstellen der digitalen Daten stets vorhanden war, auch der Autor (Chr. Rinne) ist hier nur Autodidakt. 

Rechnen Sie mit Fehlern im originalen Datenbestand und einer ggf. nicht optimalen Struktur oder erwarten Sie auch nicht die von Ihnen bevorzugte Struktur. Korrektur von Fehler und Anpassungen der Struktur erfolgen sicher am besten im originalen Arbeitsumfeld, also CAD.

Neben AutoCAD gibt es teils kostengünstigere Alternativen, u.a.:

 - BricsCAD [https://www.bricsys.com]
 - MegaCAD [https://www.megacad.de/]
 
# Jakob-Uffrecht-Straße

## AutoCAD Quelldatei (dxf)

Es handelt sich um einen mehrperiodigen Siedlungs- und Bestattungsplatz. Untersucht wurden gut 8.300 m² mit 589 Befunden, überwiegend der Bronzezeit (316), 11 eindeutig neolithischen Befunden, darunter ein doppeltes Grabensystem, 260 nicht weiter datierten oder allgemein urgeschichtlichen und zwei neuzeitlichen Befunden. Zu dem CAD Plan liegen für jede Ausgrabung eine Datenbank (MS Access) mit weiteren Informationen vor. Diese Daten können nach der Aufarbeitung des CAD Planes mit den dann eindeutig benannten Befunden verbunden werden. Dies ist aber nicht Teil dieses Skriptes. 

![Abb. 1 CAD-Datei Jacob-Uffrecgt-Straße in AutoCAD](./img/03_JUff_cad_overview.png)

Die Zeichnung enthält 171 Polylinien (2D), 33 Kreise (2D), 263 Absatztexte (MText), 361 Linien (3D), 239 Schraffuren, 427 Blockreferenzen, 810 Polylinien (3D), 497 einfache Texte und 369 Punkte (3D). In dieser Liste fallen vor allem zwei Objektypen auf, die Kreise und der Absatztext. Die Kreise wurden für einige Befunde verwendet und liegen als flache Geometrie auf einer sinnvollen Höhe. Der Absatztext wurde bei einer Maßnahme für die Befundnummern verwendet. Da es sich um keine "normale" Geometrie handelt und nur die Textbox aber nicht der Text einen Lagebezug zu den Koordinaten der Grabung hat muss dies noch in AutoCAD aufgelöst werden. 
Ebenfalls interessant, auch mit Blick auf die Umsetzung in SpatiaLite, sind  als 2D-Polylinien mit Erhebung vorliegende Befunde. Nutzen Sie ```_qselect``` mit den Optionen Objekttyp: Polylinie und der Eigenschaft Layer=Befund, um diese pauschal auszuwählen und mit einer Farbvorgabe, z.B. Magenta, deutlich hervorzuheben.  

```{r 'Table 1 List of layers in the dwg.', echo=FALSE}
tab01<-read.table("./data-raw/JUff_layer.tab", header = TRUE, sep = "\t", dec = ",")
# if output is html table as interactive datatable else table with limit
if (knitr::is_html_output()) {
  DT::datatable(tab01, filter = "top", options=list(pagelength=10), caption="Liste der
 Planzeichnungen und erstellten DWG-Dateien.")
} else {
  knitr::kable(tab01)
}
```

Eine weitere Kontrolle ergibt:

- Die Anzahl der Layer ist überschaubar, eine Trennung nach den Grabungsflächen ist nicht erfolgt, die Namen sind leider nicht ganz stringent, vor allem die Befundnummern sind mehrfach vertreten.
- Einige Namen verweisen auf konkrete Objekte und entsprechen damit nicht der scheinbar allgemein angewendeten Nomenklatur. 
- Es sind keine weiteren BKS (Benutzerkoordinatensysteme) definiert, die Koordinaten lassen ein GKB Zone 4 vermuten (das Elipsoidmodell ergibt sich daraus aber nicht).
- Die Einheit ist erwartbar in Millimeter statt den verwendeten Meter.
- Zahlreiche Befundlinien sind nicht geschlossen, auf dem Befundlayer liegen auch Kreise.
- Die Befundnummern sind über die einzelnen Ausgrabungen nicht fortlaufend vergeben, es gibt somit doppelte Befundnummern in der nördlichen und südlichen Fläche. 
- Die Ansicht von der Seite offenbart das größte Problem. Vielfach laufen Polygone von der realen Höhe auf 0 runter.  Daneben sind aber auch in der Grabung mehrere Höhenbereiche der Objekte mit einzelnen Verbindungslinien zu erkennen. Falsche Prismenhöhe beim Messen?

Es ist vor allem dieses letzte Problem, das bei der nachfolgenden Aufarbeitung besonders betrachtet werden soll. 

*Wichtig* Der MText wird weder von SpatiaLite noch von QGIS beim Import der DXF-Datei erkannt. Der Export dieser Objekte in AutoCAD über "Extras > Datenextraktion" ist möglich, der Inhalt wird aber auf den Ursprung der Textbox bezogen und die ggf. mehrzeiligen Texte werden als ein Textfeld hieran angehängt wodurch sich jede Zeile in Abhängigkeit der Texthöhe zunehmend von der Koordinate entfernt. Es empfiehlt sich, MText mit dem Befehl ```ursprung (_explode)``` in einfachen Text aufzulösen. Damit wird er auch beim Import der DXF-Datei je Zeile als Text erkannt und dem Einfügepunkt, meist der linke Ursprung der Basislinie, zugewiesen.

Um MText pauschal in Text umzuwandeln selektieren sie diesen pauschal mit ```qselect```, Anwenden auf: Ganze Zeichnung, Objekttyp: MText, Eigenschaft: Farbe = VonLayer, "In neuen Auswahlsatz einfügen" und [OK]. Danach den Befehl ```ursprung``` für die ausgewählten Objekte eingeben und ausführen. Da unter Umständen MText nicht die Farbe des Layers gehabt haben kann sollten Sie erneut alles Markieren und im Fenster der Eigenschaften (``eigenschaften```) im oberen drop-down die Anzahl der vorhandenen Objekttypen auf MText kontrollieren.

## SpatiaLite GUI

Nach dem Start der GUI bitte "Menu > Create a new (empty) SQLite DB" ausführen. In diese wird die dxf-Datei mit der gesamten Ausgrabung importiert: "Menu > Advanced > Import DXF drawings". Im Fenster zum Import bitte folgende Angaben: (x) Import selected DXF drawing file only, SRID: 31467, [v] Append to already existing tables, Dimensions: (x) authomatic 2D/3D, (x) mixed layers, Special Rings handling (x) none. Diese Angaben beziehen sich auf den aktuellen Import und müssen ggf. angepasst werden. Die Option 'mixed layers' trennt nur die Typen (Punkt, Linie Polygon, Text), die Layer werden als Attribut (Spalte) angelegt. Die Alternative trennt erst die Layer und dann nach Typen, erstellt also das x-Fache der vorhandenen CAD-Layer als Tabellen.

Als Ergebnis sind folgende Tabellen mit den Spalten *feature_id*, *filename*, *layer* und *geometry* vorhanden:

- hatch_layer_2d
- hatch_layer_2d_pattern
- line_layer_3d
- point_layer_3d
- polyg_layer_3d
- text_layer_3d

### Datenkontrolle

Visualisieren Sie den Inhalt der Geometrietabellen in QGIS. Die Option "Map preview" im Kontextmenü zu jeder Geometriespalte der Tabellen in SpatiaLite ist oft hilfreich, bietet aber weniger Möglichkeiten. Ergänzend wird in SpatiaLite für jede Tabelle eine zusammenfassende Übersicht der Daten generiert. 

Die Tabelle **hatch_layer_2d** scheint ein vollständiges(?) Abbild der dokumentierten Befunde. Sie resultiert aus den Schraffuren zur Datierung oder Befundansprache, die auf jeweils eigenen Layern in AutoCAD abgelegt wurden. Diese Informationen sind nett, sollten aber als Sachinformationen später aus den vorhandenen Datenbanken an die Befundnummern angehängt werden (join). Einige Geometrien scheinen fehlerhaft (NULL).

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Select layer, GeometryType(geometry) as geomtype, Count(*) as n 
from hatch_layer_2d
group by 1, 2;
```

Die Tabelle **hatch_layer_2d_pattern** sieht ähnlich aus, liefert aber nur zwei Geometrien, die überwiegenden Fälle sind NULL. 

In AutoCAD bestehen **Füllungen** (Pattern) wie bei vielen Grafikprogrammen aus zwei Elemente: der Kontur (Umgrenzung) und der Füllung. AutoCAD verwendet überwiegend Schraffuren, teils komplexe Kombinationen aus Linien, Polygonen und Punkten. Daneben gibt es die Füllung "solid", die eher eine Ausnahme darstellt. Erstere finden sich in der Tabelle mit mit der Ergänzung "_pattern"- letztere in der Tabelle ohne die Extension. Schraffuren sind in AutoCAD Flächen und damit sind diese Geometrien auch hier 2D. 

- Die vorgenannten Tabellen sind damit weitgehend wertlos, denn die 2D Geometrie ist ohne z-Wert unzureichend und die Sachinformationen stehen in der zugehörigen Datenbank des Projektes. 

Die Tabelle **line_layer_3d** ist von zentraler Bedeutung und zeigt außer der nicht stringenten Benennung der Layer keine Auffälligkeiten. Allerdings irritiert der mangelhafte Bezug der Profile zu den Layern (00Profil, Profile). Zudem sind offenbar zahlreiche Befunde nur als Linien erkannt worden. Die Profile weisen mit "Ansichtshaken" auf die jeweils dokumentierten Seite hin.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select layer, GeometryType(geometry) as geomtype, Count(*) as n 
from line_layer_3d
group by 1, 2;
```

Die Tabelle **point_layer_3d** enthält 3D-Punkte, die durch die Layerbezeichnungen teilweise von Bedeutung sind. Überwiegend sind es Höhenwerte der einzelnen Befunde die aber keinen Planumsbezug oder benannten Befundbezuge haben und mit den vorliegenden z-Polygonen für die Befunde überflüssig sind. Von interesse erscheinen die Verweise auf Funde (Keramik, Knochen) und Messbildnägel für die Photgrammetrie. 

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select layer, GeometryType(geometry) as geomtype, Count(*) as n 
from point_layer_3d
group by 1, 2;
```

Die Tabelle **polyg_layer_3d** ist von zentraler Bedeutung. Es handelt sich überwiegend um Befunde und einige Flächengrenzen auf unterschiedlichen Layern. Irritierend ist ein Profilpolygon und ein als Polygon dokumentiertes Keramikfargment. Bei ersterem  handelt es sich um zwei, gemeinsam als Kasten ausgehobene Profile zu zwei dicht beieinander liegenden Befunden.  

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select layer, GeometryType(geometry) as geomtype, Count(*) as n 
from polyg_layer_3d
group by 1, 2;
```

Die Tabelle **text_layer_3d** hat zu den oben genannten Spalten noch *label* und *rotation*. Es sind überwiegend die Befund- und Profilnummern, dazu einige weitere Beschriftungen. Die im CAD-Plan als Block mit Attribute gesetzten Niv-Werte sind nicht dabei und müssen über die Datenextraktion und die resultierende CSV-Liste wieder importiert werden.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select layer, GeometryType(geometry) as geomtype, Count(*) as n 
from text_layer_3d
group by 1, 2;
```

### Topologie prüfen und reparieren

Zur Datenbereinigung werden in allen Geometriespalten pauschal ungültige Geometrien repariert.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Begin transaction;
Update line_layer_3d
 set geometry = SanitizeGeometry(geometry);
Update point_layer_3d
 set geometry = SanitizeGeometry(geometry);
Update polyg_layer_3d
 set geometry = SanitizeGeometry(geometry);
Update text_layer_3d
 set geometry = SanitizeGeometry(geometry);
Commit;
```

In der Tabelle **line_layer_3d**  bleiben vier Fälle, die nur aus zwei identischen Punkten bestehen. Diese sind schlicht wertlos und werden gelöscht.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Begin transaction;
select *, IsValidReason(geometry), st_AsText(geometry) from line_layer_3d
where isvalid(geometry) <> 1;
Delete from line_layer_3d
where isvalid(geometry) <> 1;
Commit;
```

In der Tabelle *polyg_layer_3d* sind zwei sich selbst überschneidende Gemoetrien. Die visuelle Prüfung zeigt erst kein offensichtliches Problem, in einem Fall ist bei sehr kleinem Maßstab eine Kreuzung der Kontur durch sehr dicht gesetzte Punkte zu erkennen. Bei der Einmessung wurde das Prisma entweder zu stark geneigt, wodurch der Messpunkt hinter den vorangehenden berechnet wurde oder aber der Endpunkt der Linie wurde über versehentlich den Startpunkt hinaus gemessen. Beides kann leicht passieren und ist hier sicher nicht die Ausnahme. 

Eine schnelle, zielorientierte Lösung scheint angebracht. Zuerst wird die Funktion st_makevalid() angewendet. Diese erstellt bei Überschneidungen aber ein Multipolygon und damit hier nicht zulässige Geometrien die auszuschließen sind. 

Das Polygon wird mit der Funktion ST_SimplifyPreserveTopology() unter Wahrung der Topologie und einer relativ geringen Toleranz von 0.05 m vereinfacht. Da hierbei aber alle Punkte des Polygons berücksichtigt werden weicht die Fläche doch erkennbar vom Original ab und es werden zudem mit der Funktion ST_Snap() die Knoten und die Kanten erneut an das original mit der selben Toleranz gefangen. Im Ergebnis liegt ein valides z-Polygon sehr großer Ähnlichkeit vor. 

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Begin transaction;
-- Probleme lokalisieren
select *, IsValidReason(geometry) from polyg_layer_3d
  where IsValid(geometry) <> 1;
-- Die erste einfache Problemlösung
Update polyg_layer_3d
  set geometry = ST_MakeValid(geometry)
  where IsValid(geometry) <> 1 and CastToSingle(ST_MakeValid(geometry)) not null;
-- Die zweite einfache Problemlösung im Vergleich
select st_area(ST_SimplifyPreserveTopology(geometry,0.05)) as simple_area, 
 st_area(geometry) as orig_area, 
 st_area(st_snap(ST_SimplifyPreserveTopology(geometry,0.05),geometry,0.05)) 
   as snap_simple_area,
 geometrytype(st_snap(ST_SimplifyPreserveTopology(geometry,0.05), geometry,0.05)) 
   as snap_simple_type,
 st_isvalid(st_snap(ST_SimplifyPreserveTopology(geometry,0.05), geometry,0.05)) 
   as snap_simple_valid
from polyg_layer_3d
where isvalid(geometry) <> 1;
Commit;
```

| simple_area | orig_area | snap_simple_area | snap_simple_type | snap_simple_valid |
| ---------:| ---------:| ---------:|:---------:| ---------:|
| 1.699869 | 1.729045 | 1.729621 | POLYGON Z | 1 |

Das verbleibende ungültige Polygon wird mit dieser letzten Methode repariert.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Update polyg_layer_3d
  set geometry = st_snap(ST_SimplifyPreserveTopology(geometry,0.05),geometry,0.05)
  where isvalid(geometry) <> 1;
```

Alternativ könnten die aus ST_MakeValid() resultierenden Multipolygone aufgelöst, verglichen als auch bewertet und resultierend nur das repräsentative zum Original aufgehoben werden. Der Aufwand ist hier deutlich größer. Für die hier aufgezeigte Problemlösung muss aber:
- das eingangs dargestellte Problem kleiner Überschneidungen vorliegen und
- eine dem Maßstab als auch der Dimension angemessene Toleranz gewählt werden. 

### Höhenfehler korrigieren

Problem: Einzelne Punkte von Linien oder Polygone wurden an anderen Objekten gefangen oder von Hand gezeichnet, damit haben diese erkennbar einen falschen Z-Wert. Zum Beispiel:

- Die als Blöcke mit Attribut um die nördliche Grabungsfläche auf der Obrfläche eingemessenen Niv-Werte liegen bei 52,3 m im Westen und zwischen 53,0 und 53,4 m im Norden und Osten. Befundgrenzen sollten demnach mindestens 0,3 m unter diesen Werten liegen. 
- Im Norden grenzen einige Befunde an die Schnittgrenze und die Befundlinien des Planum 1 fangen die Schnittgrenze auf dem Planum 0. 
- Die Ansichtshaken der Profile sind von Hand gezeichnet und fallen damit auf die Höhe Null.
- Einige Befunde scheinen von Hand entlang gemessene Befundgrenzen konstruiert worden zu sein wobei die ohne Objektfang erstellen Knoten die Höhe 0 haben. 

Daneben kann auch das grundsätzliche Problem einer falschen Prismenhöhe vorliegen. Daran schließt sich die Frage nach dem ursprünglich, richtigen z-Wert an, die aber nur näherungsweise beantwortet werden kann. Mögliche, annähernd korrekte Werte sind die nicht bei 0 liegenden z-Werte vor und hinter dem Knoten, der Durchschnitt oder Median der z-Wert des Polygons ohne die eindeutig "falschen" Werte oder der z-Wert des nächsten gemessenen Höhenwertes oder oder oder. Dazu kommt noch das Problem großen Polygonen wir der Grabungsfläche, die bei größzügiger Vermessung durch aus einen deutlichen Höhenunterschied von Punkt zu Punkt aufweisen können.  

#### Tabelle Blöcke mit Attribut \newline

Importieren wir deshalb als erstes die in AutoCAD exportierten Blöcke mit Attribut (Datenextraktion). Über das Menü "Menu > Advanced > Load CSV/TXT" rufen Sie das Importfenster auf, wählen die Datei "JUff_blockattr.csv", Table name: block_layer_3d, [x] First line contains ..., Text separator: [o] none, Column seperaor: [o] Comma, Decimal separator: Point und Charset Encoding: UTF-8 (ganz am Ende). Die Spalte sind Namen (Blockname), HÖHE (Attribut), Layer (Layer des Blocks), Position_X/Y/Z (Koordinaten des Blocks) und Nummer (Attribut). Nachfolgend werden zuerst eine Geometrie aus den Koordinaten und dann ein Überblick über die vorhandenen z-Werte erstellt.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Begin transaction;
Select AddGeometryColumn('block_layer_3d', 'geometry', 31468, 'POINTZ', 'XYZ');
Update block_layer_3d 
  set geometry = ST_GeomFromText('POINTZ(' || "Position_X" || ' ' || 
  "Position_Y" || ' ' || "Position_Z" || ')', 31468);
select max(HÖHE) as max_H, min(HÖHE) as min_H, max(Position_Z) as max_Z,
  sum(Position_Z) / count(Position_Z) as mean_Z, min(Position_Z) as min_Z
from block_layer_3d group by name;
Commit;
```

| Name | max_H | min_H | max_Z | mean_Z | min_Z |
| ----- |---:| ---:| ---:| ----:| ---:|
| HP_FERTIG_OBERKANTE | 53.690 | 50.540 | 53.832 | 51.724 | 0.126 |
| HP_OHNE_SYMBOL | 51.450 | 51.450 | 51.590 | 51.590 | 51.590 |
| MESSPUNKT |  |  | 52.920 | 52.507 | 50.977 |

Insgesamt scheinen die Messwerte plausibel zwischen 51 m und 54 m über NN zu liegen, doch auch hier gibt es bei den gemessenen z-Werten offensichtlich falsche Werte nahe 0.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select max(st_maxz(geometry)) as max_maxz,
max(st_minz(geometry)) as max_minz, 
sum(st_maxz(geometry) - st_minz(geometry)) / count (*) as mean_diff,
min(st_maxz(geometry) - st_minz(geometry)) as min_diff,
max(st_maxz(geometry) - st_minz(geometry)) as max_diff
from line_layer_3d;
```

| max_maxz | max_minz | mean_diff | min_diff | max_diff |
| --------:| --------:| ---------:| --------:| --------:|
| 105.604000 | 105.604000 | 3.323629 | 0.000000 | 52.732000 |

Die selbe Abfrage, nur für die Tabelle polyg_layer_3d.

| max_maxz | max_minz | mean_diff | min_diff | max_diff |
| --------:| --------:| ---------:| --------:| --------:|
| 53.757953 | 53.026502 | 0.703233 | 0.000000 | 51.742000 |

Beginnen wir mit der Tabelle **block_layer_3d** und vertrauen wir darauf, dass die dargestellten, sichtbaren Höhenwerte visuell geprüft wurden und damit korrekt sein sollten. Wir verschaffen uns einen Überblick, indem wir die Differenz zwischen dargestelltem und gemessenen Wert (HÖHE - Position_Z) in Klassen von 1 cm zusammenfassen.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select count(*) as n, round((HÖHE - Position_Z)*100, 0) as diff_cm 
from block_layer_3d 
where abs(HÖHE - Position_Z) > 0.01
group by round((HÖHE - Position_Z)*100, 0);
```

| diff_cm | -152 | -114 | -21 | -18 | -17 | -16 | -15 | -14 | -13 | -9 | 22 | 5157 |
| :---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: | ---: |
| n | 1 | 1 | 1 | 1 | 1 | 1 | 2 | 283 | 7 | 1 | 1 | 1 |

Das transponierte Ergebnis zeigt sehr zahlreiche Abweichungen um -14 cm und nur vereinzelt über +/- 15 cm hinaus. Die Häufung bei -14 cm weist auf ein strukturelles Problem, für das aber keine Lösung unmittelbar auf der Hand liegt. Auch wenn die Differenz bis 15 cm eigentlich nicht vorhanden sein sollte wird diese nachfolgend ignoriert und nur die um mehr als +/- 14 cm abweichenden Messwerte mit den Angaben aus HÖHE korrigiert 

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Update block_layer_3d 
  set geometry = ST_GeomFromText('POINTZ(' || "Position_X" || ' ' || 
  "Position_Y" || ' ' || "HÖHE" || ')', 31468)
  where abs(HÖHE - Position_Z) > 0.14;
```

Die z-Werte aller Punkte liegen nun in einem plausiblen Wertebereich: Min.: 50.677, Max.: 53.829, Mittelw.: 51.981.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select min(ST_Z(geometry)) as min_z, max(ST_Z(geometry)) as max_z, 
  sum(ST_Z(geometry))/count(*) as mean_z
  from block_layer_3d;
```

#### Tabelle line_layer_3d \newline

Wie bei den Punkten ist die grundlegende Frage: Was erachten wir als falsch und wollen es korrigieren?  Zwei Parameter lassen sich leicht berechnen: die Differenz innerhalb der Linie und die Differenz bezogen auf die Länge der Linie.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select feature_id, layer, st_maxz(geometry) - st_minz(geometry) as d, 
	st_minz(geometry) as min_z, st_maxz(geometry) as max_z, 
	st_npoints(geometry) as n_points, st_length(geometry) as length,
	st_length(geometry) / (st_maxz(geometry) - st_minz(geometry)) as l_d
from line_layer_3d
where d > 0.3 or l_d < 15
order by l_d desc;
```

Am Anfang der Liste stehen lange Linien bei denen ein Höhenunterschied zwischen 0.3 und 0.6 m durchaus plausibel ist.  So ab einem Wert von kleiner als 15 für den Quotienten aus Länge zu Höhendifferenz wird es fraglich (feature_id 52) und bei dem Quotienten unter 13 (feature_id 14) vermutlich falsch. Für die Bearbeitung ergeben sich zwei Optionen: 1. Sie Schreiben die feature_id's der Linien in einen Filter und bearbeiten jede Linie in QGIS von Hand. 2. Sie verändern die Werte halbautomatisch und kontrollieren. 

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select group_concat(feature_id)
from line_layer_3d
where st_maxz(geometry) - st_minz(geometry) > 0.3 or 
 st_length(geometry) / (st_maxz(geometry) - st_minz(geometry)) < 15;
```

Zuerst der Weg der reinen Handarbeit: Kopieren Sie zuerst die Liste der feature_id's der vorangehenden Abfrage in ein Protokoll Ihrer Änderungen am Datenbestand. Übertragen Sie die Filterbedingung nach ```where``` mit *copy 'n paste*  in [Abfrage erstellen] unter dem Register Quelle bei den Eigenschaften des Layers in QGIS. Danach sehen Sie nur noch die potentiell falschen Linien und können diese editieren. Wählen Sie im Editiermodus das Stützpunktwerkzeug und markieren Sie mit einem rechten Mausklick eine Linie. Danach sollte sich ein Fenster mit der tabellarischen Liste der Koordinaten für jeden Knoten dieser Linie öffnen wo Sie dann die Wert verändern können.

Im vorliegenden Fall sind vor allem die vielen kurzen Profilinien die Masse des Problems. Sortiert nach dem kleinsten z-Wert fallen die ersten 55 Linien mit einem Wert weit unter 50 deutlich aus dem Rahmen des plausiblen. Ich verändere nachfolgend die Filterbedingung dahingehend, wobei aber mindestens ein plausibler z-Wert von über 50 m über NN vorliegen soll und schreibe alle betroffenen Linien in eine temporäre Tabelle. Je nach Anforderung können Sie ergänzend auch auf die Länge der Linie st_length(geometry), die Anzal der Knoten st_npoints(geometry) oder auch weitere Eigenschaften filtern.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Begin transaction;
Drop table if exists line_err;
Create table line_err as
  select * from line_layer_3d
  where st_minz(geometry) < 50 and st_maxz(geometry) > 50;
Select RecoverGeometryColumn('line_err', 'geometry', 31468, 'linestringz', 'xyz');
Commit;
```

Danach werden die Linien in Multipoints aufgelöst und diese wiederum in eine Tabelle mit fortlaufenden Koordinaten. Für den letzten Schritt wird ein join zur Tabelle [ElementaryGeometries](https://www.gaia-gis.it/fossil/libspatialite/wiki?name=VirtualElementary) erstellt. Hierbei werden jedes mal die Geometrien in der datenbank registriert und abschließend eine Tabelle zur visuellen Kontrolle erstellt.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Begin transaction;
-- Create table with multipoints per line
Drop table if exists line_err_multipoints;
Create table line_err_multipoints as 
  select feature_id as line_feature_id, layer, st_dissolvepoints(geometry) as geometry
  from line_err;
Select RecoverGeometryColumn('line_err_multipoints', 'geometry', 31468, 
   'multipointz', 'xyz');
-- Create table of individual points with a join  to ElementaryGeometries 
Drop table if exists line_err_points;
create table line_err_points as 
SELECT lmp.line_feature_id, lmp.rowid, e.item_no, e.geometry,
  ST_x(e.geometry) as x, ST_y(e.geometry) as y, ST_Z(e.geometry) AS z
FROM line_err_multipoints AS lmp
JOIN ElementaryGeometries AS e ON (e.f_table_name = 'line_err_multipoints'
AND e.origin_rowid = lmp.rowid);
Select RecoverGeometryColumn('line_err_points', 'geometry', 31468, 'pointz', 'xyz');
select * from line_err_points;
commit;
```

Die Tabelle enthält die ursprungliche *feature_id* der Linie, die *rowid* des ursprünglichen Multipoints und einen bei 0 beginnenden Zähler für jeden Knoten einer Linie. Die nächsten Schritt sind von der Überlegung her einfach: Ersetze jeden nicht plausiblen z-Wert durch den Mittelwert der plausiblen z-Werte der zugehörigen Linie. Schreibe danach die Punkteometrie neu und aggregiere die Punkte für jede ehemaligen Linie wieder zu einer Linie. Vergessen Sie nicht ggf. die Tabelle der genuin falschen z-Werte oder mindestens die *feature_id* der editierten Linien in einem Protokoll zu speichern (s.o.).

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Begin transaction;
Drop table if exists line_err_points_new;
-- Create a new table with new z-values
Create table line_err_points_new as
-- counter for rowid and point_item, mean z and new z-value, order of case matters
with recursive point (mean_z, rid, z_new, item) as (
-- only to initialise the counters
 select 
  (select sum(z) / count(z) from line_err_points 
    where rowid = 1 and z > 50 and z < 55) as mean_z, 
  0 as rid,
  NULL as z_new,
  -1 as item 
 union all
-- get the values or count + 1 if point_item does not exist 
 select
  case when (select z from line_err_points 
               where rowid = rid and item_no = item + 1) not null
   then mean_z
   else (select sum(z) / count(z) from line_err_points 
           where rowid = rid + 1 and z > 50 and z < 55)
   end as mean_z, 
  case when (select z from line_err_points 
               where rowid = rid and item_no = item + 1) not null
   then rid
   else rid + 1
   end as rid, 
  case when (select z from line_err_points 
               where rowid = rid and item_no = item + 1) > 50
   then (select z from line_err_points where rowid = rid and item_no = item + 1)
   else mean_z
   end as z_new, 
  case when (select z from line_err_points 
               where rowid = rid and item_no = item + 1) not null
   then item + 1
   else -1
   end as item 
 from point
-- set the limit for the recursion
  where rid <= (select max(rowid) from line_err_points))
-- do something
Select a.rid, b.line_feature_id, b.item_no, a.mean_z, a.z_new, b.z, b.x, b.y 
 from point as a
 inner join line_err_points as b on a.rid = b.rowid and a.item = b.item_no;
-- End of create table and now show the content
Select * from line_err_points_new;
Commit;
```

Kontrollieren Sie in der resultierenden Tabelle stichprobenartig zahlreiche z-Werte. Sollte das alles gut aussehen erstellen wir daraus eine neue Tabelle von Linien der ursprünglichen *feature_id*.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Begin transaction;
Drop table if exists line_err_new;
Create table line_err_new as
  Select line_feature_id as feature_id, 
  MakeLine(MakePointZ(x, y, z_new, 31468)) as geometry 
  from line_err_points_new
  group by line_feature_id;
Select RecoverGeometryColumn('line_err_new', 'geometry', 31468, 'linestringz', 'xyz');
Commit;
```

Zwischenergebnis nochmals kontrollieren und dann die alte Geometrie durch die veränderte Geometrie ersetzen.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
Update line_layer_3d as a
set geometry = (select geometry from line_err_new as b 
  where b.feature_id = a.feature_id)
where a.feature_id in (select feature_id from line_err_new);  
```

Filtern Sie danach erneut die Linien mit weiterhin potentiell falschen Höhenwerten und nehmen sie die notwendigen Änderungen von Hand vor. Dies können Sie entweder wie oben dargestellt in QGIS tun (s.o.). Der wesentliche Vorteil, sie sehen die Linien im Kontext und können z.B. bewusst an die Anschlussinie fangen. Oder aber Sie generieren erneut eine Tabelle mit ausgelesenen Korrdinaten je Knoten, editieren diese Tabelle von Hand anstelle der Rekursionsabfrage, archivieren diese Tabelle als Protokoll Ihrer Änderungen und generieren hieraus wie zuvor eine Tabelle neuer Linien. Noch 33 Linien haben eine internen Höhendifferenz von mehr als 30 cm. Nach der Visualisierung in QGIS sind es u.a. einige Befunde an der nördlichen Grabungsgrenze und die Linien des neolithischen Grabensystems.

```{sql, eval=FALSE, connection=juffdb, include=TRUE}
select group_concat(feature_id)
from line_layer_3d
where st_maxz(geometry) - st_minz(geometry) > 0.3;
```

#### Tabelle polyg_layer_3d \newline

Der Prozess wird analog zu den Tabelle der Linien durchgeführt. Entsprechend müssen die Schritte nicht erläutert und nur bedingt kommentiert werden.



# Literatur